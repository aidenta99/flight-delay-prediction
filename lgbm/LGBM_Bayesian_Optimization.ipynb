{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d97b6c-b8bc-4d7a-91f0-fb8aea097748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic tools \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#tuning hyperparameters\n",
    "from bayes_opt import BayesianOptimization  \n",
    "\n",
    "#building models\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88874857-4a29-4a67-93ab-89729335dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07a3a75-7f95-4482-904e-52c9ef1b4910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df_train_validation = pd.read_csv(\"final_train_val.csv\", low_memory=False, index_col=\"id\")\n",
    "df_test = pd.read_csv(\"final_test.csv\", low_memory=False, index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714664e0-b920-445e-95f8-1ce3afa30e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 174.72 Mb (73.8% reduction)\n",
      "Mem. usage decreased to 30.90 Mb (73.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_train_validation = reduce_mem_usage(df_train_validation) \n",
    "df_test = reduce_mem_usage(df_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a8aea7-4d73-4885-a458-5ce076a5f2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>SCHEDULED_ARRIVAL</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>LATITUDE_origin</th>\n",
       "      <th>LONGITUDE_origin</th>\n",
       "      <th>...</th>\n",
       "      <th>AIRLINE_NK</th>\n",
       "      <th>AIRLINE_OO</th>\n",
       "      <th>AIRLINE_UA</th>\n",
       "      <th>AIRLINE_US</th>\n",
       "      <th>AIRLINE_VX</th>\n",
       "      <th>AIRLINE_WN</th>\n",
       "      <th>scaled_DEPARTURE_TIME</th>\n",
       "      <th>scaled_WHEELS_OFF</th>\n",
       "      <th>scaled_SCHEDULED_TIME</th>\n",
       "      <th>scaled_DISTANCE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>430</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>61.187500</td>\n",
       "      <td>-150.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.251953</td>\n",
       "      <td>-1.628906</td>\n",
       "      <td>0.921387</td>\n",
       "      <td>1.161133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2336</td>\n",
       "      <td>10</td>\n",
       "      <td>12.0</td>\n",
       "      <td>750</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>33.937500</td>\n",
       "      <td>-118.4375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.626953</td>\n",
       "      <td>-1.629883</td>\n",
       "      <td>1.763672</td>\n",
       "      <td>2.443359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>840</td>\n",
       "      <td>20</td>\n",
       "      <td>16.0</td>\n",
       "      <td>806</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.625000</td>\n",
       "      <td>-122.3750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.607422</td>\n",
       "      <td>-1.605469</td>\n",
       "      <td>1.831055</td>\n",
       "      <td>2.394531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>258</td>\n",
       "      <td>20</td>\n",
       "      <td>15.0</td>\n",
       "      <td>805</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>33.937500</td>\n",
       "      <td>-118.4375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.610352</td>\n",
       "      <td>-1.610352</td>\n",
       "      <td>1.820312</td>\n",
       "      <td>2.460938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>25</td>\n",
       "      <td>11.0</td>\n",
       "      <td>320</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>47.437500</td>\n",
       "      <td>-122.3125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.599609</td>\n",
       "      <td>-1.604492</td>\n",
       "      <td>1.258789</td>\n",
       "      <td>1.161133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818548</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1180</td>\n",
       "      <td>2359</td>\n",
       "      <td>11.0</td>\n",
       "      <td>600</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>33.937500</td>\n",
       "      <td>-118.4375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.256836</td>\n",
       "      <td>-1.635742</td>\n",
       "      <td>1.326172</td>\n",
       "      <td>1.591797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818549</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1192</td>\n",
       "      <td>2359</td>\n",
       "      <td>11.0</td>\n",
       "      <td>520</td>\n",
       "      <td>79.0</td>\n",
       "      <td>33.937500</td>\n",
       "      <td>-118.4375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.471680</td>\n",
       "      <td>-1.475586</td>\n",
       "      <td>0.876465</td>\n",
       "      <td>1.061523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818550</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1480</td>\n",
       "      <td>2359</td>\n",
       "      <td>8.0</td>\n",
       "      <td>608</td>\n",
       "      <td>107.0</td>\n",
       "      <td>45.593750</td>\n",
       "      <td>-122.6250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.443359</td>\n",
       "      <td>-1.402344</td>\n",
       "      <td>1.416016</td>\n",
       "      <td>1.708984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818551</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1637</td>\n",
       "      <td>2359</td>\n",
       "      <td>12.0</td>\n",
       "      <td>609</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47.437500</td>\n",
       "      <td>-122.3125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.614258</td>\n",
       "      <td>-1.617188</td>\n",
       "      <td>1.426758</td>\n",
       "      <td>1.780273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818552</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1903</td>\n",
       "      <td>2359</td>\n",
       "      <td>14.0</td>\n",
       "      <td>534</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>29.984375</td>\n",
       "      <td>-95.3125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.620117</td>\n",
       "      <td>-1.621094</td>\n",
       "      <td>1.708008</td>\n",
       "      <td>1.973633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2818553 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MONTH  DAY  DAY_OF_WEEK  FLIGHT_NUMBER  SCHEDULED_DEPARTURE  \\\n",
       "id                                                                     \n",
       "0            1    1            4             98                    5   \n",
       "1            1    1            4           2336                   10   \n",
       "2            1    1            4            840                   20   \n",
       "3            1    1            4            258                   20   \n",
       "4            1    1            4            135                   25   \n",
       "...        ...  ...          ...            ...                  ...   \n",
       "2818548      6   30            2           1180                 2359   \n",
       "2818549      6   30            2           1192                 2359   \n",
       "2818550      6   30            2           1480                 2359   \n",
       "2818551      6   30            2           1637                 2359   \n",
       "2818552      6   30            2           1903                 2359   \n",
       "\n",
       "         TAXI_OUT  SCHEDULED_ARRIVAL  ARRIVAL_DELAY  LATITUDE_origin  \\\n",
       "id                                                                     \n",
       "0            21.0                430          -22.0        61.187500   \n",
       "1            12.0                750           -9.0        33.937500   \n",
       "2            16.0                806            5.0        37.625000   \n",
       "3            15.0                805           -9.0        33.937500   \n",
       "4            11.0                320          -21.0        47.437500   \n",
       "...           ...                ...            ...              ...   \n",
       "2818548      11.0                600           -8.0        33.937500   \n",
       "2818549      11.0                520           79.0        33.937500   \n",
       "2818550       8.0                608          107.0        45.593750   \n",
       "2818551      12.0                609            9.0        47.437500   \n",
       "2818552      14.0                534           -8.0        29.984375   \n",
       "\n",
       "         LONGITUDE_origin  ...  AIRLINE_NK  AIRLINE_OO  AIRLINE_UA  \\\n",
       "id                         ...                                       \n",
       "0               -150.0000  ...         0.0         0.0         0.0   \n",
       "1               -118.4375  ...         0.0         0.0         0.0   \n",
       "2               -122.3750  ...         0.0         0.0         0.0   \n",
       "3               -118.4375  ...         0.0         0.0         0.0   \n",
       "4               -122.3125  ...         0.0         0.0         0.0   \n",
       "...                   ...  ...         ...         ...         ...   \n",
       "2818548         -118.4375  ...         0.0         0.0         1.0   \n",
       "2818549         -118.4375  ...         0.0         0.0         1.0   \n",
       "2818550         -122.6250  ...         0.0         0.0         1.0   \n",
       "2818551         -122.3125  ...         0.0         0.0         1.0   \n",
       "2818552          -95.3125  ...         0.0         0.0         1.0   \n",
       "\n",
       "         AIRLINE_US  AIRLINE_VX  AIRLINE_WN  scaled_DEPARTURE_TIME  \\\n",
       "id                                                                   \n",
       "0               0.0         0.0         0.0               1.251953   \n",
       "1               0.0         0.0         0.0              -1.626953   \n",
       "2               1.0         0.0         0.0              -1.607422   \n",
       "3               0.0         0.0         0.0              -1.610352   \n",
       "4               0.0         0.0         0.0              -1.599609   \n",
       "...             ...         ...         ...                    ...   \n",
       "2818548         0.0         0.0         0.0               1.256836   \n",
       "2818549         0.0         0.0         0.0              -1.471680   \n",
       "2818550         0.0         0.0         0.0              -1.443359   \n",
       "2818551         0.0         0.0         0.0              -1.614258   \n",
       "2818552         0.0         0.0         0.0              -1.620117   \n",
       "\n",
       "         scaled_WHEELS_OFF  scaled_SCHEDULED_TIME  scaled_DISTANCE  \n",
       "id                                                                  \n",
       "0                -1.628906               0.921387         1.161133  \n",
       "1                -1.629883               1.763672         2.443359  \n",
       "2                -1.605469               1.831055         2.394531  \n",
       "3                -1.610352               1.820312         2.460938  \n",
       "4                -1.604492               1.258789         1.161133  \n",
       "...                    ...                    ...              ...  \n",
       "2818548          -1.635742               1.326172         1.591797  \n",
       "2818549          -1.475586               0.876465         1.061523  \n",
       "2818550          -1.402344               1.416016         1.708984  \n",
       "2818551          -1.617188               1.426758         1.780273  \n",
       "2818552          -1.621094               1.708008         1.973633  \n",
       "\n",
       "[2818553 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2267c52f-7f85-4112-b922-d417fedb56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split: for LGBM\n",
    "df_train, df_validation = train_test_split(df_train_validation, test_size=0.20, random_state = 42)\n",
    "X_train, y_train = df_train.drop(\"ARRIVAL_DELAY\", axis=1), df_train[\"ARRIVAL_DELAY\"]\n",
    "X_val, y_val = df_validation.drop(\"ARRIVAL_DELAY\", axis=1), df_validation[\"ARRIVAL_DELAY\"]\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a62e4dc2-01c6-48cb-8173-70c97431b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_parameter_opt_lgbm(X, y, init_round=15, opt_round=25, n_folds=3, random_seed=6, output_process=False):\n",
    "    # prepare data\n",
    "    train_data = lgbm.Dataset(data=X, label=y, free_raw_data=False)\n",
    "    # parameters\n",
    "    def lgbm_eval(learning_rate,num_leaves, feature_fraction, bagging_fraction, max_depth, max_bin, min_data_in_leaf, min_sum_hessian_in_leaf, subsample):\n",
    "        params = {'application':'regression_l2', 'metric':'auc'}\n",
    "        params['learning_rate'] = max(min(learning_rate, 1), 0)\n",
    "        params['num_leaves'] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['max_bin'] = int(round(max_depth))\n",
    "        params['min_data_in_leaf'] = int(round(min_data_in_leaf))\n",
    "        params['min_sum_hessian_in_leaf'] = min_sum_hessian_in_leaf\n",
    "        params['subsample'] = max(min(subsample, 1), 0)\n",
    "        \n",
    "        cv_result = lgbm.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval=200, metrics=['auc'])\n",
    "        return max(cv_result['auc-mean'])\n",
    "     \n",
    "    lgbmBO = BayesianOptimization(lgbm_eval, {'learning_rate': (0.001, 1.0),\n",
    "                                            'num_leaves': (2, 2**10),\n",
    "                                            'feature_fraction': (0.1, 1),\n",
    "                                            'bagging_fraction': (0.1, 1),\n",
    "                                            'max_depth': (2, 10),\n",
    "                                            'max_bin':(10,200),\n",
    "                                            'min_data_in_leaf': (10, 200),\n",
    "                                            'min_sum_hessian_in_leaf':(0,400),\n",
    "                                            'subsample': (0.01, 1.0)}, random_state=200)\n",
    "\n",
    "    \n",
    "    #n_iter: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n",
    "    #init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space.\n",
    "    \n",
    "    lgbmBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    \n",
    "    model_auc=[]\n",
    "    for model in range(len( lgbmBO.res)):\n",
    "        model_auc.append(lgbmBO.res[model]['target'])\n",
    "    \n",
    "    # return best parameters\n",
    "    return lgbmBO.res[pd.Series(model_auc).idxmax()]['target'],lgbmBO.res[pd.Series(model_auc).idxmax()]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45991e05-cc2f-44b7-9249-a4ea85f3c585",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | learni... |  max_bin  | max_depth | min_da... | min_su... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9528690311665032, subsample=0.4615201756036703 will be ignored. Current value: bagging_fraction=0.9528690311665032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9528690311665032, subsample=0.4615201756036703 will be ignored. Current value: bagging_fraction=0.9528690311665032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9528690311665032, subsample=0.4615201756036703 will be ignored. Current value: bagging_fraction=0.9528690311665032\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 998\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9528690311665032, subsample=0.4615201756036703 will be ignored. Current value: bagging_fraction=0.9528690311665032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9528690311665032, subsample=0.4615201756036703 will be ignored. Current value: bagging_fraction=0.9528690311665032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9528690311665032, subsample=0.4615201756036703 will be ignored. Current value: bagging_fraction=0.9528690311665032\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 998\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9528690311665032, subsample=0.4615201756036703 will be ignored. Current value: bagging_fraction=0.9528690311665032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9528690311665032, subsample=0.4615201756036703 will be ignored. Current value: bagging_fraction=0.9528690311665032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9528690311665032, subsample=0.4615201756036703 will be ignored. Current value: bagging_fraction=0.9528690311665032\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 998\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9528690311665032, subsample=0.4615201756036703 will be ignored. Current value: bagging_fraction=0.9528690311665032\n",
      "[LightGBM] [Info] Start training from score 5.991501\n",
      "[LightGBM] [Info] Start training from score 5.989361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/lightgbm/engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 5.988886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8864  \u001b[0m | \u001b[0m 0.9529  \u001b[0m | \u001b[0m 0.2539  \u001b[0m | \u001b[0m 2.973   \u001b[0m | \u001b[0m 91.38   \u001b[0m | \u001b[0m 76.89   \u001b[0m | \u001b[0m 10.54   \u001b[0m | \u001b[0m 143.0   \u001b[0m | \u001b[0m 364.1   \u001b[0m | \u001b[0m 0.4615  \u001b[0m |\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9528690311665032, subsample=0.4615201756036703 will be ignored. Current value: bagging_fraction=0.9528690311665032\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9836224382424957, subsample=0.2580000042232922 will be ignored. Current value: bagging_fraction=0.9836224382424957\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9836224382424957, subsample=0.2580000042232922 will be ignored. Current value: bagging_fraction=0.9836224382424957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Cannot change max_bin after constructed Dataset handle.\n",
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9836224382424957, subsample=0.2580000042232922 will be ignored. Current value: bagging_fraction=0.9836224382424957\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9836224382424957, subsample=0.2580000042232922 will be ignored. Current value: bagging_fraction=0.9836224382424957\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 459\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9836224382424957, subsample=0.2580000042232922 will be ignored. Current value: bagging_fraction=0.9836224382424957\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9836224382424957, subsample=0.2580000042232922 will be ignored. Current value: bagging_fraction=0.9836224382424957\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9836224382424957, subsample=0.2580000042232922 will be ignored. Current value: bagging_fraction=0.9836224382424957\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 459\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9836224382424957, subsample=0.2580000042232922 will be ignored. Current value: bagging_fraction=0.9836224382424957\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9836224382424957, subsample=0.2580000042232922 will be ignored. Current value: bagging_fraction=0.9836224382424957\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9836224382424957, subsample=0.2580000042232922 will be ignored. Current value: bagging_fraction=0.9836224382424957\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 459\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9836224382424957, subsample=0.2580000042232922 will be ignored. Current value: bagging_fraction=0.9836224382424957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/lightgbm/engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 5.991501\n",
      "[LightGBM] [Info] Start training from score 5.989361\n",
      "[LightGBM] [Info] Start training from score 5.988886\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8823  \u001b[0m | \u001b[0m 0.9836  \u001b[0m | \u001b[0m 0.8306  \u001b[0m | \u001b[0m 4.93    \u001b[0m | \u001b[0m 185.4   \u001b[0m | \u001b[0m 31.76   \u001b[0m | \u001b[0m 170.8   \u001b[0m | \u001b[0m 48.49   \u001b[0m | \u001b[0m 314.7   \u001b[0m | \u001b[0m 0.258   \u001b[0m |\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9836224382424957, subsample=0.2580000042232922 will be ignored. Current value: bagging_fraction=0.9836224382424957\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.18642673913849137, subsample=0.4252313651032907 will be ignored. Current value: bagging_fraction=0.18642673913849137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.18642673913849137, subsample=0.4252313651032907 will be ignored. Current value: bagging_fraction=0.18642673913849137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Cannot change max_bin after constructed Dataset handle.\n",
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.18642673913849137, subsample=0.4252313651032907 will be ignored. Current value: bagging_fraction=0.18642673913849137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.18642673913849137, subsample=0.4252313651032907 will be ignored. Current value: bagging_fraction=0.18642673913849137\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1127\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.18642673913849137, subsample=0.4252313651032907 will be ignored. Current value: bagging_fraction=0.18642673913849137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.18642673913849137, subsample=0.4252313651032907 will be ignored. Current value: bagging_fraction=0.18642673913849137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.18642673913849137, subsample=0.4252313651032907 will be ignored. Current value: bagging_fraction=0.18642673913849137\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1127\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.18642673913849137, subsample=0.4252313651032907 will be ignored. Current value: bagging_fraction=0.18642673913849137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.18642673913849137, subsample=0.4252313651032907 will be ignored. Current value: bagging_fraction=0.18642673913849137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.18642673913849137, subsample=0.4252313651032907 will be ignored. Current value: bagging_fraction=0.18642673913849137\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1127\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.18642673913849137, subsample=0.4252313651032907 will be ignored. Current value: bagging_fraction=0.18642673913849137\n",
      "[LightGBM] [Info] Start training from score 5.991501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/lightgbm/engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 5.989361\n",
      "[LightGBM] [Info] Start training from score 5.988886\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.9128  \u001b[0m | \u001b[95m 0.1864  \u001b[0m | \u001b[95m 0.8991  \u001b[0m | \u001b[95m 4.13    \u001b[0m | \u001b[95m 108.5   \u001b[0m | \u001b[95m 87.6    \u001b[0m | \u001b[95m 119.9   \u001b[0m | \u001b[95m 180.0   \u001b[0m | \u001b[95m 272.7   \u001b[0m | \u001b[95m 0.4252  \u001b[0m |\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.18642673913849137, subsample=0.4252313651032907 will be ignored. Current value: bagging_fraction=0.18642673913849137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6763541179700744, subsample=0.805623782185316 will be ignored. Current value: bagging_fraction=0.6763541179700744\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6763541179700744, subsample=0.805623782185316 will be ignored. Current value: bagging_fraction=0.6763541179700744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Cannot change max_bin after constructed Dataset handle.\n",
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6763541179700744, subsample=0.805623782185316 will be ignored. Current value: bagging_fraction=0.6763541179700744\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6763541179700744, subsample=0.805623782185316 will be ignored. Current value: bagging_fraction=0.6763541179700744\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 986\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6763541179700744, subsample=0.805623782185316 will be ignored. Current value: bagging_fraction=0.6763541179700744\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6763541179700744, subsample=0.805623782185316 will be ignored. Current value: bagging_fraction=0.6763541179700744\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6763541179700744, subsample=0.805623782185316 will be ignored. Current value: bagging_fraction=0.6763541179700744\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 986\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6763541179700744, subsample=0.805623782185316 will be ignored. Current value: bagging_fraction=0.6763541179700744\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6763541179700744, subsample=0.805623782185316 will be ignored. Current value: bagging_fraction=0.6763541179700744\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6763541179700744, subsample=0.805623782185316 will be ignored. Current value: bagging_fraction=0.6763541179700744\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 986\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6763541179700744, subsample=0.805623782185316 will be ignored. Current value: bagging_fraction=0.6763541179700744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/lightgbm/engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 5.991501\n",
      "[LightGBM] [Info] Start training from score 5.989361\n",
      "[LightGBM] [Info] Start training from score 5.988886\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8754  \u001b[0m | \u001b[0m 0.6764  \u001b[0m | \u001b[0m 0.5978  \u001b[0m | \u001b[0m 0.5281  \u001b[0m | \u001b[0m 193.5   \u001b[0m | \u001b[0m 76.35   \u001b[0m | \u001b[0m 139.1   \u001b[0m | \u001b[0m 131.7   \u001b[0m | \u001b[0m 12.53   \u001b[0m | \u001b[0m 0.8056  \u001b[0m |\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6763541179700744, subsample=0.805623782185316 will be ignored. Current value: bagging_fraction=0.6763541179700744\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9755462707288031, subsample=0.8559475937048635 will be ignored. Current value: bagging_fraction=0.9755462707288031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Cannot change max_bin after constructed Dataset handle.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9755462707288031, subsample=0.8559475937048635 will be ignored. Current value: bagging_fraction=0.9755462707288031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9755462707288031, subsample=0.8559475937048635 will be ignored. Current value: bagging_fraction=0.9755462707288031\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9755462707288031, subsample=0.8559475937048635 will be ignored. Current value: bagging_fraction=0.9755462707288031\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 303\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9755462707288031, subsample=0.8559475937048635 will be ignored. Current value: bagging_fraction=0.9755462707288031\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9755462707288031, subsample=0.8559475937048635 will be ignored. Current value: bagging_fraction=0.9755462707288031\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9755462707288031, subsample=0.8559475937048635 will be ignored. Current value: bagging_fraction=0.9755462707288031\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 303\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9755462707288031, subsample=0.8559475937048635 will be ignored. Current value: bagging_fraction=0.9755462707288031\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9755462707288031, subsample=0.8559475937048635 will be ignored. Current value: bagging_fraction=0.9755462707288031\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9755462707288031, subsample=0.8559475937048635 will be ignored. Current value: bagging_fraction=0.9755462707288031\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 303\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9755462707288031, subsample=0.8559475937048635 will be ignored. Current value: bagging_fraction=0.9755462707288031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/lightgbm/engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 5.991501\n",
      "[LightGBM] [Info] Start training from score 5.989361\n",
      "[LightGBM] [Info] Start training from score 5.988886\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8221  \u001b[0m | \u001b[0m 0.9755  \u001b[0m | \u001b[0m 0.3046  \u001b[0m | \u001b[0m 3.246   \u001b[0m | \u001b[0m 60.46   \u001b[0m | \u001b[0m 20.39   \u001b[0m | \u001b[0m 89.62   \u001b[0m | \u001b[0m 266.4   \u001b[0m | \u001b[0m 207.9   \u001b[0m | \u001b[0m 0.8559  \u001b[0m |\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9755462707288031, subsample=0.8559475937048635 will be ignored. Current value: bagging_fraction=0.9755462707288031\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9345922867790175, subsample=0.04064614663672882 will be ignored. Current value: bagging_fraction=0.9345922867790175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Cannot change max_bin after constructed Dataset handle.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9345922867790175, subsample=0.04064614663672882 will be ignored. Current value: bagging_fraction=0.9345922867790175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9345922867790175, subsample=0.04064614663672882 will be ignored. Current value: bagging_fraction=0.9345922867790175\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9345922867790175, subsample=0.04064614663672882 will be ignored. Current value: bagging_fraction=0.9345922867790175\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 567\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9345922867790175, subsample=0.04064614663672882 will be ignored. Current value: bagging_fraction=0.9345922867790175\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9345922867790175, subsample=0.04064614663672882 will be ignored. Current value: bagging_fraction=0.9345922867790175\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9345922867790175, subsample=0.04064614663672882 will be ignored. Current value: bagging_fraction=0.9345922867790175\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 567\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9345922867790175, subsample=0.04064614663672882 will be ignored. Current value: bagging_fraction=0.9345922867790175\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9345922867790175, subsample=0.04064614663672882 will be ignored. Current value: bagging_fraction=0.9345922867790175\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9345922867790175, subsample=0.04064614663672882 will be ignored. Current value: bagging_fraction=0.9345922867790175\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 567\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9345922867790175, subsample=0.04064614663672882 will be ignored. Current value: bagging_fraction=0.9345922867790175\n",
      "[LightGBM] [Info] Start training from score 5.991501\n",
      "[LightGBM] [Info] Start training from score 5.989361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/lightgbm/engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 5.988886\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8604  \u001b[0m | \u001b[0m 0.9346  \u001b[0m | \u001b[0m 0.284   \u001b[0m | \u001b[0m 4.531   \u001b[0m | \u001b[0m 154.8   \u001b[0m | \u001b[0m 41.24   \u001b[0m | \u001b[0m 146.6   \u001b[0m | \u001b[0m 130.3   \u001b[0m | \u001b[0m 64.73   \u001b[0m | \u001b[0m 0.04065 \u001b[0m |\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9345922867790175, subsample=0.04064614663672882 will be ignored. Current value: bagging_fraction=0.9345922867790175\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5922163999347385, subsample=0.8433313512183651 will be ignored. Current value: bagging_fraction=0.5922163999347385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Cannot change max_bin after constructed Dataset handle.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5922163999347385, subsample=0.8433313512183651 will be ignored. Current value: bagging_fraction=0.5922163999347385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5922163999347385, subsample=0.8433313512183651 will be ignored. Current value: bagging_fraction=0.5922163999347385\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5922163999347385, subsample=0.8433313512183651 will be ignored. Current value: bagging_fraction=0.5922163999347385\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 555\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5922163999347385, subsample=0.8433313512183651 will be ignored. Current value: bagging_fraction=0.5922163999347385\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5922163999347385, subsample=0.8433313512183651 will be ignored. Current value: bagging_fraction=0.5922163999347385\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5922163999347385, subsample=0.8433313512183651 will be ignored. Current value: bagging_fraction=0.5922163999347385\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 555\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5922163999347385, subsample=0.8433313512183651 will be ignored. Current value: bagging_fraction=0.5922163999347385\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5922163999347385, subsample=0.8433313512183651 will be ignored. Current value: bagging_fraction=0.5922163999347385\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5922163999347385, subsample=0.8433313512183651 will be ignored. Current value: bagging_fraction=0.5922163999347385\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 555\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5922163999347385, subsample=0.8433313512183651 will be ignored. Current value: bagging_fraction=0.5922163999347385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/lightgbm/engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 5.991501\n",
      "[LightGBM] [Info] Start training from score 5.989361\n",
      "[LightGBM] [Info] Start training from score 5.988886\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8923  \u001b[0m | \u001b[0m 0.5922  \u001b[0m | \u001b[0m 0.4519  \u001b[0m | \u001b[0m 4.294   \u001b[0m | \u001b[0m 189.0   \u001b[0m | \u001b[0m 39.93   \u001b[0m | \u001b[0m 118.1   \u001b[0m | \u001b[0m 174.9   \u001b[0m | \u001b[0m 255.3   \u001b[0m | \u001b[0m 0.8433  \u001b[0m |\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5922163999347385, subsample=0.8433313512183651 will be ignored. Current value: bagging_fraction=0.5922163999347385\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3203321167413814, subsample=0.5700324234601654 will be ignored. Current value: bagging_fraction=0.3203321167413814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Cannot change max_bin after constructed Dataset handle.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.3203321167413814, subsample=0.5700324234601654 will be ignored. Current value: bagging_fraction=0.3203321167413814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.3203321167413814, subsample=0.5700324234601654 will be ignored. Current value: bagging_fraction=0.3203321167413814\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3203321167413814, subsample=0.5700324234601654 will be ignored. Current value: bagging_fraction=0.3203321167413814\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1046\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3203321167413814, subsample=0.5700324234601654 will be ignored. Current value: bagging_fraction=0.3203321167413814\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3203321167413814, subsample=0.5700324234601654 will be ignored. Current value: bagging_fraction=0.3203321167413814\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3203321167413814, subsample=0.5700324234601654 will be ignored. Current value: bagging_fraction=0.3203321167413814\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1046\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3203321167413814, subsample=0.5700324234601654 will be ignored. Current value: bagging_fraction=0.3203321167413814\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3203321167413814, subsample=0.5700324234601654 will be ignored. Current value: bagging_fraction=0.3203321167413814\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3203321167413814, subsample=0.5700324234601654 will be ignored. Current value: bagging_fraction=0.3203321167413814\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1046\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3203321167413814, subsample=0.5700324234601654 will be ignored. Current value: bagging_fraction=0.3203321167413814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/lightgbm/engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 5.991501\n",
      "[LightGBM] [Info] Start training from score 5.989361\n",
      "[LightGBM] [Info] Start training from score 5.988886\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9109  \u001b[0m | \u001b[0m 0.3203  \u001b[0m | \u001b[0m 0.7826  \u001b[0m | \u001b[0m 4.301   \u001b[0m | \u001b[0m 138.7   \u001b[0m | \u001b[0m 81.32   \u001b[0m | \u001b[0m 114.5   \u001b[0m | \u001b[0m 147.4   \u001b[0m | \u001b[0m 300.1   \u001b[0m | \u001b[0m 0.57    \u001b[0m |\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3203321167413814, subsample=0.5700324234601654 will be ignored. Current value: bagging_fraction=0.3203321167413814\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=0.01 will be ignored. Current value: bagging_fraction=0.1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=0.01 will be ignored. Current value: bagging_fraction=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Cannot change max_bin after constructed Dataset handle.\n",
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=0.01 will be ignored. Current value: bagging_fraction=0.1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=0.01 will be ignored. Current value: bagging_fraction=0.1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1264\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=0.01 will be ignored. Current value: bagging_fraction=0.1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=0.01 will be ignored. Current value: bagging_fraction=0.1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=0.01 will be ignored. Current value: bagging_fraction=0.1\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1264\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=0.01 will be ignored. Current value: bagging_fraction=0.1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=0.01 will be ignored. Current value: bagging_fraction=0.1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=0.01 will be ignored. Current value: bagging_fraction=0.1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1264\n",
      "[LightGBM] [Info] Number of data points in the train set: 1503228, number of used features: 29\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=0.01 will be ignored. Current value: bagging_fraction=0.1\n",
      "[LightGBM] [Info] Start training from score 5.991501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rico/anaconda3/envs/flight/lib/python3.8/site-packages/lightgbm/engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 5.989361\n",
      "[LightGBM] [Info] Start training from score 5.988886\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/flight/lib/python3.8/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0.1, 0.95, 3.5811529335615577, 119.99645991673124, 100.0, 192.75859536390595, 181.544605941748, 316.08709901698955, 0.01)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5106/1075084878.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopt_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes_parameter_opt_lgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5106/1456775712.py\u001b[0m in \u001b[0;36mbayes_parameter_opt_lgbm\u001b[0;34m(X, y, init_round, opt_round, n_folds, random_seed, output_process)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mlgbmBO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mmodel_auc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flight/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flight/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flight/lib/python3.8/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5106/1456775712.py\u001b[0m in \u001b[0;36mlgbm_eval\u001b[0;34m(learning_rate, num_leaves, feature_fraction, bagging_fraction, max_depth, max_bin, min_data_in_leaf, min_sum_hessian_in_leaf, subsample)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subsample'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mcv_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flight/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[1;32m    639\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    640\u001b[0m         \u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_train_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{key}-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flight/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mhandler_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboosters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandler_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flight/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_valid\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   3269\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m         \"\"\"\n\u001b[0;32m-> 3271\u001b[0;31m         return [item for i in range(1, self.__num_dataset)\n\u001b[0m\u001b[1;32m   3272\u001b[0m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[1;32m   3273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flight/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3270\u001b[0m         \"\"\"\n\u001b[1;32m   3271\u001b[0m         return [item for i in range(1, self.__num_dataset)\n\u001b[0;32m-> 3272\u001b[0;31m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0m\u001b[1;32m   3273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'split'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flight/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   3787\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3788\u001b[0m             \u001b[0mtmp_out_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3789\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterGetEval(\n\u001b[0m\u001b[1;32m   3790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt_params = bayes_parameter_opt_lgbm(X_train, y_train, init_round=5, opt_round=10, n_folds=3, random_seed=6)\n",
    "print(opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "000920be-c798-4c4b-baec-c50761eb7460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8962938098165422,\n",
       " {'bagging_fraction': 0.8,\n",
       "  'feature_fraction': 0.95,\n",
       "  'learning_rate': 1.0,\n",
       "  'max_bin': 90.0,\n",
       "  'max_depth': 30.0,\n",
       "  'min_data_in_leaf': 20.0,\n",
       "  'min_sum_hessian_in_leaf': 100.0,\n",
       "  'num_leaves': 200.0,\n",
       "  'subsample': 0.01})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b09cd615-a4b7-41c1-b1d9-e98ce7345872",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('opt_params.pickle', 'wb') as f:\n",
    "    pickle.dump(opt_params, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
