{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15fc56b2-f6cd-426b-ac86-edc2f329461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9572aaa-adcc-4d20-a741-5c794f7199be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Function to reduce the required memory of a dataframe.\n",
    "    Returns the dataframe with reduced size.\n",
    "    \"\"\"\n",
    "    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f6898-2c67-4561-9849-1e31e05a87f0",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da71a46-89bd-4339-90c2-4aa4fedab5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-processed data and drop NAs\n",
    "df_train_validation = pd.read_csv(\"final_train_val.csv\", low_memory=False, index_col=\"id\")\n",
    "df_train_validation = df_train_validation.dropna()\n",
    "df_test = pd.read_csv(\"final_test.csv\", low_memory=False, index_col=\"id\")\n",
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01bf7d6a-dd5c-4d2f-b1e8-e770ad927515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 222.72 Mb (69.5% reduction)\n",
      "Mem. usage decreased to 39.65 Mb (69.3% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Reduce size of dataframes\n",
    "df_train_validation = reduce_mem_usage(df_train_validation)\n",
    "df_test = reduce_mem_usage(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f26a51-148c-43ce-9822-877ec1749dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get series of origin and destination airports\n",
    "orig_airports = pd.Series(df_train_validation['ORIGIN_AIRPORT'])\n",
    "dest_airports = pd.Series(df_train_validation['DESTINATION_AIRPORT'])\n",
    "\n",
    "# Get a list of all unique airports and create an ID mapping\n",
    "all_airports = orig_airports.append(dest_airports).unique()\n",
    "airport_ids = pd.Series(list(range(len(all_airports))), index=all_airports)\n",
    "airport_id_dict = {airport_ids[a]: a for a in all_airports}\n",
    "\n",
    "# Change from IATA codes to generated IDs\n",
    "orig_airports = orig_airports.apply(lambda x: airport_ids[x])\n",
    "df_train_validation[\"ORIGIN_AIRPORT\"] = orig_airports\n",
    "dest_airports = dest_airports.apply(lambda x: airport_ids[x])\n",
    "df_train_validation[\"DESTINATION_AIRPORT\"] = dest_airports\n",
    "dist_airports = pd.Series(df_train_validation['scaled_DISTANCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65d05121-6008-4c92-944e-2a5fa52ed0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test sets\n",
    "df_train, df_validation = train_test_split(df_train_validation, test_size=0.20, random_state = 42)\n",
    "X_train, y_train = df_train.drop(\"ARRIVAL_DELAY\", axis=1), df_train[\"ARRIVAL_DELAY\"]\n",
    "X_val, y_val = df_validation.drop(\"ARRIVAL_DELAY\", axis=1), df_validation[\"ARRIVAL_DELAY\"]\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dbf520-eabc-4010-b95e-193b70b7d74f",
   "metadata": {},
   "source": [
    "## Airport features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25c8d210-5c87-40d3-a580-70dcb8ee73ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the destination and origin airports are the same \n",
    "assert(set(df_train_validation[\"DESTINATION_AIRPORT\"].unique()) == set(df_train_validation[\"ORIGIN_AIRPORT\"].unique()))\n",
    "# we can use only origin airports\n",
    "node_data = df_train_validation[[\"ORIGIN_AIRPORT\", \"LATITUDE_origin\", \"LONGITUDE_origin\"]]\n",
    "node_data = node_data.drop_duplicates(ignore_index=True).values[:,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29296703-0b76-4160-bb88-ddae1fbc98fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4457c3dd-7c45-4dd2-8aa6-5d50b8e87b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract edge embedding\n",
    "edge_data = df_train_validation[['MONTH', 'DAY', 'DAY_OF_WEEK', 'FLIGHT_NUMBER', 'SCHEDULED_DEPARTURE', 'TAXI_OUT', 'SCHEDULED_ARRIVAL', 'ARRIVAL_DELAY', \n",
    "                     'DEPARTURE_DELAY', 'AIRLINE_AA', 'AIRLINE_AS', 'AIRLINE_B6', 'AIRLINE_DL', 'AIRLINE_EV', 'AIRLINE_F9', 'AIRLINE_HA', 'AIRLINE_MQ',\n",
    "                     'AIRLINE_DL', 'AIRLINE_EV', 'AIRLINE_F9', 'AIRLINE_HA', 'AIRLINE_MQ', 'AIRLINE_NK', 'AIRLINE_OO', 'AIRLINE_UA', 'AIRLINE_US', 'AIRLINE_VX',\n",
    "                     'AIRLINE_WN', 'scaled_DEPARTURE_TIME', 'scaled_WHEELS_OFF', 'scaled_SCHEDULED_TIME']].values\n",
    "# Extract edge labels, i.e. target\n",
    "edge_labels = df_train_validation['ARRIVAL_DELAY'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a17a2cb-fecf-4555-a71e-8d335b388298",
   "metadata": {},
   "source": [
    "# Graph learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a524847c-0dfd-425f-af1f-9b9fca31ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import dgl\n",
    "from torch import nn\n",
    "from dgl.data import register_data_args, load_data\n",
    "from dgl.nn.pytorch.conv import SAGEConv\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcf5f12a-e2d0-455b-bbe8-797c1fbfb906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph\n",
    "src = orig_airports.to_numpy()\n",
    "dst = dest_airports.to_numpy()\n",
    "edge_pred_graph = dgl.graph((src,dst))\n",
    "edge_pred_graph.ndata['feature'] = torch.from_numpy(node_data)\n",
    "edge_pred_graph.edata['feature'] = torch.from_numpy(edge_data)\n",
    "edge_pred_graph.edata['label'] = torch.from_numpy(edge_labels.reshape(-1,1))\n",
    "edge_pred_graph.edata['train_mask'] = torch.zeros(len(df_train_validation), dtype=torch.bool)\n",
    "edge_pred_graph.edata['train_mask'][0:len(df_train)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1815c694-7004-47f8-b9ac-417b137c027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "class DotProductPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies the dot product between all edges to compute the labels\n",
    "    \"\"\"\n",
    "    def forward(self, graph, h):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            return graph.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7abaf76e-5c56-43f7-ad0c-9a3997fec3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    \"\"\"\n",
    "    A two layer SAGEConv network\n",
    "    \"\"\"\n",
    "    def __init__(self, in_feats, hid_feats, out_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = dglnn.SAGEConv(\n",
    "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
    "        self.conv2 = dglnn.SAGEConv(\n",
    "            in_feats=hid_feats, out_feats=hid_feats, aggregator_type='mean')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2920904-6ecb-46d6-95cd-d476f1e98df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super().__init__()\n",
    "        self.sage = SAGE(in_features, hidden_features, out_features)\n",
    "        self.pred = DotProductPredictor()\n",
    "    def forward(self, g, x):\n",
    "        h = self.sage(g, x)\n",
    "        return self.pred(g, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e45aa1b-97bf-4e48-b1ab-1ccfcb167847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample:  Predicted: 262936.875 Actual: -22.0\n",
      "27546929152.0\n",
      "Sample:  Predicted: 2418.515869140625 Actual: -22.0\n",
      "2991716.5\n",
      "Sample:  Predicted: 1.1659562587738037 Actual: -22.0\n",
      "1682.2607421875\n",
      "Sample:  Predicted: 1.4757596254348755 Actual: -9.0\n",
      "1680.5155029296875\n",
      "Sample:  Predicted: 1.6079038381576538 Actual: 8.0\n",
      "1650.9813232421875\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "node_features = edge_pred_graph.ndata['feature']\n",
    "edge_label = edge_pred_graph.edata['label']\n",
    "train_mask = edge_pred_graph.edata['train_mask']\n",
    "model = Model(2, 100, 1)\n",
    "model = model.float()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.04)\n",
    "\n",
    "# Training\n",
    "for epoch in range(50):\n",
    "    batch_mask = torch.zeros(train_mask.shape[0], dtype=torch.bool).bernoulli(0.4)\n",
    "    pred = model(edge_pred_graph, node_features.float())\n",
    "    loss = ((pred[batch_mask] - edge_label[batch_mask]) ** 2).mean()\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Sample: \",\"Predicted:\", pred[batch_mask][0].tolist()[0], \"Actual:\", edge_label[batch_mask][0].tolist()[0])\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "684b2e07-de60-40c1-981d-108694fba791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6576],\n",
       "        [1.6576],\n",
       "        [1.6576],\n",
       "        ...,\n",
       "        [1.6576],\n",
       "        [1.6576],\n",
       "        [1.6576]], grad_fn=<GSDDMMBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
